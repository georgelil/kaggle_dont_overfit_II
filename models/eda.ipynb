{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA - Exploratory data analysis\n",
    "So as an initial step im going to open up the data\n",
    "and have a look around... (yeah i'll try and fit it also)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import l1_min_c\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 250\n",
      "dimensions:  300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>-0.026872</td>\n",
       "      <td>0.167404</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>0.032052</td>\n",
       "      <td>0.078412</td>\n",
       "      <td>-0.036920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044652</td>\n",
       "      <td>0.126344</td>\n",
       "      <td>0.018436</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>-0.065720</td>\n",
       "      <td>-0.106112</td>\n",
       "      <td>0.046472</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>-0.128952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.480963</td>\n",
       "      <td>0.998354</td>\n",
       "      <td>1.009314</td>\n",
       "      <td>1.021709</td>\n",
       "      <td>1.011751</td>\n",
       "      <td>1.035411</td>\n",
       "      <td>0.955700</td>\n",
       "      <td>1.006657</td>\n",
       "      <td>0.939731</td>\n",
       "      <td>0.963688</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011416</td>\n",
       "      <td>0.972567</td>\n",
       "      <td>0.954229</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>1.057414</td>\n",
       "      <td>1.038389</td>\n",
       "      <td>0.967661</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>1.008099</td>\n",
       "      <td>0.971219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.319000</td>\n",
       "      <td>-2.931000</td>\n",
       "      <td>-2.477000</td>\n",
       "      <td>-2.359000</td>\n",
       "      <td>-2.566000</td>\n",
       "      <td>-2.845000</td>\n",
       "      <td>-2.976000</td>\n",
       "      <td>-3.444000</td>\n",
       "      <td>-2.768000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.804000</td>\n",
       "      <td>-2.443000</td>\n",
       "      <td>-2.757000</td>\n",
       "      <td>-2.466000</td>\n",
       "      <td>-3.287000</td>\n",
       "      <td>-3.072000</td>\n",
       "      <td>-2.634000</td>\n",
       "      <td>-2.776000</td>\n",
       "      <td>-3.211000</td>\n",
       "      <td>-3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.644750</td>\n",
       "      <td>-0.739750</td>\n",
       "      <td>-0.425250</td>\n",
       "      <td>-0.686500</td>\n",
       "      <td>-0.659000</td>\n",
       "      <td>-0.643750</td>\n",
       "      <td>-0.675000</td>\n",
       "      <td>-0.550750</td>\n",
       "      <td>-0.689500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617000</td>\n",
       "      <td>-0.510500</td>\n",
       "      <td>-0.535750</td>\n",
       "      <td>-0.657000</td>\n",
       "      <td>-0.818500</td>\n",
       "      <td>-0.821000</td>\n",
       "      <td>-0.605500</td>\n",
       "      <td>-0.751250</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>-0.754250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015500</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>-0.016500</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.009000</td>\n",
       "      <td>-0.079500</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>-0.009000</td>\n",
       "      <td>-0.132500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.620750</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.783250</td>\n",
       "      <td>0.766250</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797250</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.631500</td>\n",
       "      <td>0.650250</td>\n",
       "      <td>0.739500</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>0.794250</td>\n",
       "      <td>0.654250</td>\n",
       "      <td>0.503250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.567000</td>\n",
       "      <td>2.419000</td>\n",
       "      <td>3.392000</td>\n",
       "      <td>2.771000</td>\n",
       "      <td>2.901000</td>\n",
       "      <td>2.793000</td>\n",
       "      <td>2.546000</td>\n",
       "      <td>2.846000</td>\n",
       "      <td>2.512000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.865000</td>\n",
       "      <td>2.801000</td>\n",
       "      <td>2.736000</td>\n",
       "      <td>2.596000</td>\n",
       "      <td>2.226000</td>\n",
       "      <td>3.131000</td>\n",
       "      <td>3.236000</td>\n",
       "      <td>2.626000</td>\n",
       "      <td>3.530000</td>\n",
       "      <td>2.771000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           target           0           1           2           3           4  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000  250.000000  250.000000   \n",
       "mean     0.640000    0.023292   -0.026872    0.167404    0.001904    0.001588   \n",
       "std      0.480963    0.998354    1.009314    1.021709    1.011751    1.035411   \n",
       "min      0.000000   -2.319000   -2.931000   -2.477000   -2.359000   -2.566000   \n",
       "25%      0.000000   -0.644750   -0.739750   -0.425250   -0.686500   -0.659000   \n",
       "50%      1.000000   -0.015500    0.057000    0.184000   -0.016500   -0.023000   \n",
       "75%      1.000000    0.677000    0.620750    0.805000    0.720000    0.735000   \n",
       "max      1.000000    2.567000    2.419000    3.392000    2.771000    2.901000   \n",
       "\n",
       "                5           6           7           8  ...         290  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000  ...  250.000000   \n",
       "mean    -0.007304    0.032052    0.078412   -0.036920  ...    0.044652   \n",
       "std      0.955700    1.006657    0.939731    0.963688  ...    1.011416   \n",
       "min     -2.845000   -2.976000   -3.444000   -2.768000  ...   -2.804000   \n",
       "25%     -0.643750   -0.675000   -0.550750   -0.689500  ...   -0.617000   \n",
       "50%      0.037500    0.060500    0.183500   -0.012500  ...    0.067500   \n",
       "75%      0.660500    0.783250    0.766250    0.635000  ...    0.797250   \n",
       "max      2.793000    2.546000    2.846000    2.512000  ...    2.865000   \n",
       "\n",
       "              291         292         293         294         295         296  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000  250.000000  250.000000   \n",
       "mean     0.126344    0.018436   -0.012092   -0.065720   -0.106112    0.046472   \n",
       "std      0.972567    0.954229    0.960630    1.057414    1.038389    0.967661   \n",
       "min     -2.443000   -2.757000   -2.466000   -3.287000   -3.072000   -2.634000   \n",
       "25%     -0.510500   -0.535750   -0.657000   -0.818500   -0.821000   -0.605500   \n",
       "50%      0.091000    0.057500   -0.021000   -0.009000   -0.079500    0.009500   \n",
       "75%      0.804250    0.631500    0.650250    0.739500    0.493000    0.683000   \n",
       "max      2.801000    2.736000    2.596000    2.226000    3.131000    3.236000   \n",
       "\n",
       "              297         298         299  \n",
       "count  250.000000  250.000000  250.000000  \n",
       "mean     0.006452    0.009372   -0.128952  \n",
       "std      0.998984    1.008099    0.971219  \n",
       "min     -2.776000   -3.211000   -3.500000  \n",
       "25%     -0.751250   -0.550000   -0.754250  \n",
       "50%      0.005500   -0.009000   -0.132500  \n",
       "75%      0.794250    0.654250    0.503250  \n",
       "max      2.626000    3.530000    2.771000  \n",
       "\n",
       "[8 rows x 301 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv('../data/train.csv', index_col=0)\n",
    "test_data = pd.read_csv('../data/test.csv', index_col=0)\n",
    "\n",
    "print('samples:', len(training_data))\n",
    "print('dimensions: ', len(training_data.columns) - 1)\n",
    "\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more dimensions than samples.. \n",
    "300 dimensions... maybe too many for a histogram table, messy trying to describe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "Y = training_data.loc[:, 'target'].values\n",
    "X = training_data.drop('target', axis=1).values\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "Y = Y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_data.values\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "125\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "scores = []\n",
    "#index = np.arange(0.01, 1, .1)\n",
    "#for i in index:\n",
    "log_model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=.1, solver='liblinear')\n",
    "\n",
    "log_model.fit(X_train, y_train)\n",
    "print(log_model.score(X_test, y_test))\n",
    "    \n",
    "#plt.plot(index, scores)\n",
    "\n",
    "#index[np.argmax(scores)]\n",
    "#output = pd.Series(index=test_data.index, data=log_model.predict(X_test), name='target')\n",
    "#output.to_csv('../results/log_submission.csv', header='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a23ced630>]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#split the data into training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "estimators = round(300**1/2)\n",
    "add = []\n",
    "i_vals = range(1, 50, 1)\n",
    "for i in i_vals:\n",
    "    clf = RandomForestClassifier(n_estimators=i, max_depth=5)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    add.append(clf.score(X_test, y_test))\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "\n",
    "plt.plot(i_vals, add)\n",
    "#output = pd.Series(index=test_data.index, data=clf.predict(X_test), name='target')\n",
    "#output.to_csv('../results/rfc_submission.csv', header='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "100\n",
      "linear SVC score:  0.64\n",
      "svc score:  0.62 0.1\n",
      "svc score:  0.62 1\n",
      "svc score:  0.62 10\n",
      "svc score:  0.62 100\n",
      "svc score:  0.62 1000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "lsvc_model = LinearSVC(tol=1e-5, C=0.1)\n",
    "lsvc_model.fit(X_train, y_train)\n",
    "print('linear SVC score: ', lsvc_model.score(X_test, y_test))\n",
    "\n",
    "cs = [0.1, 1, 10, 100, 1000]\n",
    "for gamma in cs:\n",
    "    #svc = svm.SVC(kernel=kernel).fit(X, y)\n",
    "    svc_model = SVC(C=gamma, kernel='poly', degree=2000, gamma=0.1)\n",
    "    svc_model.fit(X_train, y_train)\n",
    "    print('svc score: ', svc_model.score(X_test, y_test), gamma)\n",
    "\n",
    "##output = pd.Series(index=test_data.index, data=svc_model.predict(test), name='target')\n",
    "#output.to_csv('../results/svc_submission.csv', header='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69047619 0.47619048 0.69047619 0.52380952 0.70731707 0.6097561 ]\n",
      "0.616337591947348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "sets = []\n",
    "index = np.linspace(0.01, 5, 40)\n",
    "log_model = linear_model.LogisticRegression(class_weight='balanced', C=.21, intercept_scaling=0.1, solver='liblinear')\n",
    "res = cross_val_score(log_model, X, Y, cv=6)\n",
    "print(res)\n",
    "print(np.mean(res))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.21020408163265308, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.826 (+/-0.081) for {'C': 0.1, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.833 (+/-0.050) for {'C': 0.1, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.826 (+/-0.081) for {'C': 0.11836734693877551, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.836 (+/-0.036) for {'C': 0.11836734693877551, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.824 (+/-0.080) for {'C': 0.13673469387755102, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.838 (+/-0.056) for {'C': 0.13673469387755102, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.820 (+/-0.088) for {'C': 0.15510204081632656, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.894 (+/-0.080) for {'C': 0.15510204081632656, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.817 (+/-0.091) for {'C': 0.17346938775510207, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.891 (+/-0.066) for {'C': 0.17346938775510207, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.817 (+/-0.091) for {'C': 0.19183673469387758, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.893 (+/-0.069) for {'C': 0.19183673469387758, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.825 (+/-0.105) for {'C': 0.21020408163265308, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.898 (+/-0.063) for {'C': 0.21020408163265308, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.825 (+/-0.105) for {'C': 0.2285714285714286, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.883 (+/-0.092) for {'C': 0.2285714285714286, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.825 (+/-0.105) for {'C': 0.2469387755102041, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.888 (+/-0.071) for {'C': 0.2469387755102041, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.825 (+/-0.105) for {'C': 0.2653061224489796, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.885 (+/-0.077) for {'C': 0.2653061224489796, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.825 (+/-0.105) for {'C': 0.2836734693877551, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.890 (+/-0.086) for {'C': 0.2836734693877551, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.825 (+/-0.105) for {'C': 0.3020408163265306, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.891 (+/-0.080) for {'C': 0.3020408163265306, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.825 (+/-0.105) for {'C': 0.3204081632653062, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.888 (+/-0.083) for {'C': 0.3204081632653062, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.3387755102040817, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.880 (+/-0.077) for {'C': 0.3387755102040817, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.3571428571428572, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.876 (+/-0.079) for {'C': 0.3571428571428572, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.3755102040816327, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.886 (+/-0.073) for {'C': 0.3755102040816327, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.3938775510204082, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.880 (+/-0.097) for {'C': 0.3938775510204082, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.41224489795918373, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.888 (+/-0.107) for {'C': 0.41224489795918373, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.43061224489795924, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.887 (+/-0.106) for {'C': 0.43061224489795924, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.44897959183673475, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.887 (+/-0.106) for {'C': 0.44897959183673475, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.46734693877551026, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.886 (+/-0.104) for {'C': 0.46734693877551026, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.48571428571428577, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.894 (+/-0.076) for {'C': 0.48571428571428577, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.5040816326530613, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.893 (+/-0.074) for {'C': 0.5040816326530613, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.5224489795918368, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.898 (+/-0.054) for {'C': 0.5224489795918368, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.5408163265306123, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.898 (+/-0.054) for {'C': 0.5408163265306123, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.5591836734693878, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.898 (+/-0.054) for {'C': 0.5591836734693878, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.5775510204081633, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.887 (+/-0.064) for {'C': 0.5775510204081633, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.5959183673469388, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.887 (+/-0.064) for {'C': 0.5959183673469388, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.6142857142857143, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.886 (+/-0.067) for {'C': 0.6142857142857143, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.6326530612244898, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.887 (+/-0.066) for {'C': 0.6326530612244898, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.6510204081632653, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.887 (+/-0.066) for {'C': 0.6510204081632653, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.6693877551020408, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.888 (+/-0.068) for {'C': 0.6693877551020408, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.819 (+/-0.111) for {'C': 0.6877551020408164, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.889 (+/-0.071) for {'C': 0.6877551020408164, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.7061224489795919, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.889 (+/-0.071) for {'C': 0.7061224489795919, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.7244897959183674, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.897 (+/-0.063) for {'C': 0.7244897959183674, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.7428571428571429, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.896 (+/-0.068) for {'C': 0.7428571428571429, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.7612244897959184, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.896 (+/-0.068) for {'C': 0.7612244897959184, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.7795918367346939, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.896 (+/-0.068) for {'C': 0.7795918367346939, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.7979591836734694, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.884 (+/-0.058) for {'C': 0.7979591836734694, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.8163265306122449, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.884 (+/-0.058) for {'C': 0.8163265306122449, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.8346938775510204, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.884 (+/-0.058) for {'C': 0.8346938775510204, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.8530612244897959, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.882 (+/-0.063) for {'C': 0.8530612244897959, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.8714285714285714, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.881 (+/-0.060) for {'C': 0.8714285714285714, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.889795918367347, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.881 (+/-0.060) for {'C': 0.889795918367347, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.9081632653061225, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.881 (+/-0.060) for {'C': 0.9081632653061225, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.926530612244898, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.881 (+/-0.060) for {'C': 0.926530612244898, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.9448979591836735, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.880 (+/-0.059) for {'C': 0.9448979591836735, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.963265306122449, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.880 (+/-0.059) for {'C': 0.963265306122449, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 0.9816326530612246, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.880 (+/-0.059) for {'C': 0.9816326530612246, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.816 (+/-0.119) for {'C': 1.0, 'intercept_scaling': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.880 (+/-0.059) for {'C': 1.0, 'intercept_scaling': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'solver': ['liblinear'], 'intercept_scaling': np.arange(0.1, 1, 50), 'penalty': [ 'l2', 'l1'], 'C': np.linspace(0.1, 1., 50)}\n",
    " ]\n",
    "\n",
    "log_model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1',\n",
    "                                            solver='liblinear')\n",
    "log_model.get_params().keys()\n",
    "model = GridSearchCV(log_model, param_grid, scoring='precision', cv=5, n_jobs=-1)\n",
    "model.fit(X, Y)\n",
    "print(model.best_params_)\n",
    "max(model.cv_results_['mean_test_score'])\n",
    "\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "0.8\n",
      "0.84\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "kf = RepeatedStratifiedKFold(n_splits=10, n_repeats=20, random_state=42)\n",
    "i = 0\n",
    "model = None\n",
    "for train_index, test_index in kf.split(X, Y):\n",
    "    log_model = linear_model.LogisticRegression(C=0.21, intercept_scaling=0.1, class_weight='balanced', penalty='l1', solver='liblinear')\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    log_model.fit(X_train, y_train)\n",
    "    score = log_model.score(X_test, y_test)\n",
    "    if score > i:\n",
    "        i = score\n",
    "        model = log_model\n",
    "        print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.Series(index=test_data.index, data=model.predict(test), name='target')\n",
    "output.to_csv('../results/log_rstratfold_submission.csv', header='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
